# Heatingtask
Project for the DTU course Python and High performance computing course, group 50
Due on 04 May 2025 11:55 PM
26 Feb - 4 May

Open tasks 

✅ 1. Familiarize yourself with the data.
Load and visualize the input data for a few floorplans using a separate Python script, Jupyter notebook, or your preferred tool.

✅ 2. Familiarize yourself with the provided script.
Run and time the reference implementation for a small subset of floorplans (e.g., 10–20). How long do you estimate it would take to process all the floorplans? Perform the timing as a batch job so you get reliable results.

✅ 3. Visualize the simulation results for a few floorplans.

4. Profile the reference Jacobi function using kernprof. Explain the different parts of the function and how much time each part takes.

5. Make a new Python program where you parallelize the computations over the floorplans. Use static scheduling such that each worker is assigned the same amount of floorplans to process.
You should use no more than 100 floorplans for your timing experiments. Again, use a batch job to ensure consistent results.
a) Measure the speed-up as more workers are added. Plot your speed-ups.
b) Estimate your parallel fraction according to Amdahl's law. How much (roughly) is parallelized?
c) What is your theoretical maximum speed-up according to Amdahl's law? How much of that did you achieve? How many cores did that take?
d) How long would you estimate it would take to process all floorplans using your fastest parallel solution?

6. The amount of iterations needed to reach convergence will vary from floorplan to floorplan. Re-do your parallelization experiment using dynamic scheduling.
a) Did it get faster? By how much?
b) Did the speed-up improve or worsen?

7. Implement another solution where you rewrite the Jacobi function using Numba JIT on the CPU.
a) Run and time the new solution for a small subset of floorplans. How does the performance compare to the reference?
b) Explain your function. How did you ensure your access pattern works well with the CPU cache?
c) How long would it now take to process all floorplans?

8. Implement another solution writing a custom CUDA kernel with Numba. To synchronize threads between each iteration, the kernel should only perform a single iteration of the Jacobi solver. Skip the early stopping criteria and just run for a fixed amount of iterations. Write a helper function which takes the same inputs as the reference implementation (except for the atol input which is not needed) and then calls your kernel repeatedly to perform the iterations.
a) Briefly describe your new solution. How did you structure your kernel and helper function?
b) Run and time the new solution for a small subset of floorplans. How does the performance compare to the reference?
c) How long would it now take to process all floorplans?

9. Adapt the reference solution to run on the GPU using CuPy.
a) Run and time the new solution for a small subset of floorplans. How does the performance compare to the reference?
b) How long would it now take to process all floorplans?
c) Was anything surprising about the performance?

10. Profile the CuPy solution using the nsys profiler. What is the main issue regarding performance? (Hint: see exercises from week 10) Try to fix it.

(Optional) Improve the performance of one or more of your solutions further. For example, parallelize your CPU JIT solution. Or use job arrays to parallelize a solution over multiple jobs. How fast can you get?

Process all floorplans using one of your implementations (ideally a fast one) and answer the below questions.
Hint: use Pandas to process the CSV results generated by the script.
a) What is the distribution of the mean temperatures? Show your results as histograms.
b) What is the average mean temperature of the buildings?
c) What is the average temperature standard deviation?
d) How many buildings had at least 50% of their area above 18ºC?
e) How many buildings had at least 50% of their area below 15ºC?
